//to run code
//g++ -fopenmp merge_sort.cpp -o merge_sort
//./merge_sort 50 20

#include <omp.h>
#include <stdlib.h>
#include <chrono>
#include <array>
#include <functional>
#include <iostream>
#include <string>
#include <vector> 

auto start = std::chrono::high_resolution_clock::now();
auto stop = std::chrono::high_resolution_clock::now();
auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);

using namespace std;

void p_mergesort(int *a, int i, int j);
void s_mergesort(int *a, int i, int j);
void merge(int *a, int i1, int j1, int i2, int j2);

void p_mergesort(int *a, int i, int j) {
if (i < j) {
int mid;
if ((j - i) > 1000) {
mid = (i + j) / 2;
#pragma omp task firstprivate(a, i, mid)
p_mergesort(a, i, mid);
#pragma omp task firstprivate(a, mid, j)
p_mergesort(a, mid + 1, j);
#pragma omp taskwait
merge(a, i, mid, mid + 1, j);
} else {
s_mergesort(a, i, j);
}
}
}

void parallel_mergesort(int *a, int i, int j) {
#pragma omp parallel num_threads(16)
{
#pragma omp single
p_mergesort(a, i, j);
}
}

void s_mergesort(int *a, int i, int j) {
int mid;
if (i < j) {
mid = (i + j) / 2;
s_mergesort(a, i, mid);
s_mergesort(a, mid + 1, j);
merge(a, i, mid, mid + 1, j);
}
}

void merge(int *a, int i1, int j1, int i2, int j2) {
    int size = j2 - i1 + 1;
    int* temp = new int[size]; // allocate required size dynamically

    int i = i1, j = i2, k = 0;

    while (i <= j1 && j <= j2) {
        temp[k++] = (a[i] < a[j]) ? a[i++] : a[j++];
    }

    while (i <= j1) temp[k++] = a[i++];
    while (j <= j2) temp[k++] = a[j++];

    for (i = i1, k = 0; i <= j2; i++, k++) {
        a[i] = temp[k];
    }

    delete[] temp; // free memory
}



std::string bench_traverse(std::function<void()> traverse_fn) {
    auto start = std::chrono::high_resolution_clock::now();
    traverse_fn();
    auto stop = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(stop - start);
    return std::to_string(duration.count());
}

int main(int argc, const char **argv) {

    int n, rand_max;

    // Check if command-line arguments are provided
    if (argc < 3) {
        std::cout << "Specify array length and maximum random value\n";

        // Prompt user for input if arguments are not provided
        std::cout << "Enter array length: ";
        std::cin >> n;

        std::cout << "Enter maximum random value: ";
        std::cin >> rand_max;
    } else {
        // Parse array length and maximum random value from arguments
        n = stoi(argv[1]);
        rand_max = stoi(argv[2]);
    }

    int *a = new int[n];
    int *b = new int[n];

    // Generate the random array
    for (int i = 0; i < n; i++) {
        a[i] = rand() % rand_max;
    }

    // Copy array a to b
    std::copy(a, a + n, b);

    // Output generated array details
    std::cout << "Generated random array of length " << n 
              << " with elements between 0 and " << rand_max << "\n\n";

    // Sequential Merge Sort
    std::cout << "Sequential merge sort: " 
              << bench_traverse([&] { s_mergesort(a, 0, n-1); }) 
              << "ms\n";

    cout << "Sorted array is ready =>\n";
    // Uncomment to print sorted array if needed
    // for (int i = 0; i < n; i++) {
    //     cout << a[i] << ", ";
    // }
    cout << "\n\n";

    omp_set_num_threads(16);  // Set the number of threads for parallel processing

    // Parallel Merge Sort
    std::cout << "Parallel (16) merge sort: " 
              << bench_traverse([&] { parallel_mergesort(b, 0, n-1); }) 
              << "ms\n";

    // Uncomment to print sorted parallel array if needed
    // cout << "Sorted array is =>\n";
    // for (int i = 0; i < n; i++) {
    //     cout << b[i] << ", ";
    // }

    // Clean up dynamically allocated memory
    delete[] a;
    delete[] b;

    return 0;
}



This C++ code implements parallel and sequential Merge Sort using OpenMP to measure and compare their execution times on a randomly generated array.

🔍 Overview
The program:

Takes input (array size and max random value) from CLI or user.

Generates a random array a and copies it to b.

Sorts a using sequential merge sort.

Sorts b using parallel merge sort with OpenMP (num_threads = 16).

Times and displays how long each took.

🧠 Key Concepts & Components
1. Merge Sort
A classic divide-and-conquer sorting algorithm:

Divide: Split the array into two halves.

Conquer: Recursively sort the halves.

Combine: Merge the sorted halves.

2. Parallelization with OpenMP
Used to divide sorting work across multiple threads:

#pragma omp parallel – starts a parallel region.

#pragma omp single – ensures only one thread starts the recursive calls.

#pragma omp task – creates independent sorting tasks.

#pragma omp taskwait – waits for all tasks to complete before merging.

3. Task Threshold
The line:

cpp
Copy
Edit
if ((j - i) > 1000)
ensures that only large enough subarrays are sorted in parallel, avoiding overhead on small tasks. If below this threshold, sequential sort is used.

🔧 Functions Explained
void s_mergesort(int *a, int i, int j)
Standard recursive merge sort.

void p_mergesort(int *a, int i, int j)
Recursive parallel merge sort using OpenMP tasks.

Uses firstprivate to safely pass variables to tasks.

void parallel_mergesort(int *a, int i, int j)
Initializes the parallel region.

Calls p_mergesort inside #pragma omp single to start the task tree.

void merge(int *a, int i1, int j1, int i2, int j2)
Merges two sorted subarrays: [i1..j1] and [i2..j2].

bench_traverse(std::function<void()> fn)
Times how long a function takes using std::chrono.

💡 How It Works
Example Execution: ./merge_sort 50 20
Creates an array of 50 random integers from 0 to 19.

Performs:

Sequential Merge Sort on array a

Parallel Merge Sort on array b

Measures and prints the time each takes in milliseconds.

🧪 Performance Factors
Speedup depends on array size: Larger arrays benefit more from parallelism.

Thread count: More threads (num_threads(16)) can increase speed but also overhead.

Task overhead: Avoid creating too many tiny tasks ((j - i) > 1000 helps avoid that).

Merge phase: Still inherently sequential.

📦 Compilation & Execution
sh
Copy
Edit
g++ -fopenmp merge_sort.cpp -o merge_sort
./merge_sort 1000000 10000
✅ Summary
Feature	Description
Parallelism	Achieved using OpenMP tasks.
Scalability	Limited by task granularity and merge overhead.
Efficiency	Efficient for large data due to divide-and-conquer parallelism.
Memory Usage	Uses dynamic arrays for merging.
Timing	Measures execution time using chrono.


1. Merge Sort (Divide and Conquer Algorithm)
Divide: Break the array into smaller subarrays until you reach size 1.

Conquer: Sort the subarrays.

Combine: Merge sorted subarrays to get a fully sorted array.

Time Complexity: O(n log n) in all cases (best, worst, average).

Space Complexity: O(n) due to temporary arrays used in merging.

2. Parallel Computing
A model in which multiple calculations are carried out simultaneously using multiple processing elements (threads or cores).

Benefits:

Speedup performance (especially on multi-core CPUs).

Better resource utilization.

Challenges:

Overhead of managing parallel tasks.

Data consistency and thread safety.

3. OpenMP (Open Multi-Processing)
An API for shared-memory parallel programming in C/C++ and Fortran.

Simplifies the process of creating multithreaded code using compiler directives like:

#pragma omp parallel – Create a team of threads.

#pragma omp task – Define a task for parallel execution.

#pragma omp taskwait – Wait for all child tasks to complete.

#pragma omp single – Ensure a block is executed by one thread only.

4. Task Parallelism vs Data Parallelism
Task Parallelism: Different threads execute different tasks (as in merge sort recursion).

Data Parallelism: The same operation is performed on different chunks of data (as in a parallel for loop).

5. Granularity
The size of tasks relative to the overhead of managing them.

Fine-grained tasks (very small) → High overhead.

Coarse-grained tasks (large) → More efficient but fewer tasks to parallelize.

Threshold (j - i) > 1000 controls granularity.

6. Race Condition
Occurs when multiple threads access shared data concurrently, and the final result depends on the timing of their execution.

The code avoids race conditions by not having shared writable data between threads during sort.